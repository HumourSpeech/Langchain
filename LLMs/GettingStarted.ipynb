{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1053de9b",
   "metadata": {},
   "source": [
    "Getting started with Langchain and OpenAI\n",
    "\n",
    "We will learn how to :\n",
    "\n",
    "- Setup langchain,langsmith,langserve\n",
    "- use basic components of langchain : prompt templates, models, and o/p parser\n",
    "- build a simple application with langchain\n",
    "- trace your application with langsmith\n",
    "- serve your application with langserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a56e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# os.environ[\"HUGGINGFACEHUB_API_KEY\"]=os.getenv(\"HUGGINGFACEHUB_API_KEY\")\n",
    "# os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "# os.environ[\"PPLX_API_KEY\"] = os.getenv(\"PPLX_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a7044a",
   "metadata": {},
   "source": [
    "Use the below code for OPENAI APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "204f0d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# # llm = ChatOpenAI() ## No need to pass api key explicitly as we have set it in environment variable\n",
    "# llm = ChatOpenAI(model= \"gpt-4o\")\n",
    "# print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e00aeeb",
   "metadata": {},
   "source": [
    "Use the below code for PERPLEXITY AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcafcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_perplexity import ChatPerplexity\n",
    "\n",
    "# llm = ChatPerplexity(model=\"sonar\", temperature=0.7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69fa7a2",
   "metadata": {},
   "source": [
    "Use the below code for Ollama LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f16ff22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"gemma:2b\",\n",
    "    validate_model_on_init=True,\n",
    "    temperature=0.8,\n",
    "    num_predict=256,\n",
    "    # other params ...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1a46b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOllama(model='gemma:2b', validate_model_on_init=True, num_predict=256, temperature=0.8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60272b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The translated sentence would be:\\n\\n\"Me encanta Ria\"', additional_kwargs={}, response_metadata={'model': 'gemma:2b', 'created_at': '2025-12-03T08:19:41.4308126Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6294533400, 'load_duration': 1246081200, 'prompt_eval_count': 38, 'prompt_eval_duration': 1884905700, 'eval_count': 13, 'eval_duration': 3077532700, 'logprobs': None, 'model_name': 'gemma:2b', 'model_provider': 'ollama'}, id='lc_run--e17f0cfe-0f22-4086-ad1b-97255657bbe2-0', usage_metadata={'input_tokens': 38, 'output_tokens': 13, 'total_tokens': 51})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You are a helpful translator. Translate the user sentence to spanish.\"),\n",
    "    (\"human\", \"I love Ria\"),\n",
    "]\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26451124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! It's a pleasure to meet you. How can I assist you today?\", additional_kwargs={}, response_metadata={'model': 'gemma:2b', 'created_at': '2025-12-03T08:17:44.0108497Z', 'done': True, 'done_reason': 'stop', 'total_duration': 26843985200, 'load_duration': 15076756500, 'prompt_eval_count': 29, 'prompt_eval_duration': 6869596600, 'eval_count': 19, 'eval_duration': 4416014000, 'logprobs': None, 'model_name': 'gemma:2b', 'model_provider': 'ollama'}, id='lc_run--28329cdb-5cd6-4849-a679-c426d0ec1dc0-0', usage_metadata={'input_tokens': 29, 'output_tokens': 19, 'total_tokens': 48})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [(\"system\", \"You are a chatbot.\"), (\"user\", \"Hello!\")]\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input prompt to the model\n",
    "result = llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23d09fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Sure, here's a definition of generative AI:\\n\\n**Generative AI** is a type of artificial intelligence (AI) that focuses on creating new content, such as text, images, music, and code. Unlike **predictive AI**, which is used to make accurate predictions about the future, generative AI aims to understand existing data and create new variations or derivatives.\\n\\nHere are some key characteristics of generative AI:\\n\\n* **Unsupervised learning:** Generative AI algorithms do not need labeled data to create content.\\n* **Text generation:** One of the most common applications of generative AI is in natural language processing (NLP) for text generation, translation, and question answering.\\n* **Image generation:** Generative AI can also create images, including paintings, photos, and other visual content.\\n* **Music composition:** Generative AI models are being developed to create new music pieces and even collaborate with human composers.\\n* **Code generation:** Generative AI is also being used to generate code in different programming languages.\\n\\nGenerative AI is a rapidly evolving field with significant potential to revolutionize various industries, including:\\n\\n* **Content creation:** News organizations, publishers, and businesses can use generative AI to create fresh content, such as articles and marketing\" additional_kwargs={} response_metadata={'model': 'gemma:2b', 'created_at': '2025-12-03T08:30:56.2056355Z', 'done': True, 'done_reason': 'length', 'total_duration': 60946336200, 'load_duration': 8178192600, 'prompt_eval_count': 27, 'prompt_eval_duration': 2876028700, 'eval_count': 256, 'eval_duration': 49353295600, 'logprobs': None, 'model_name': 'gemma:2b', 'model_provider': 'ollama'} id='lc_run--cb833b75-9520-4c70-86a0-475a1cf0bfa3-0' usage_metadata={'input_tokens': 27, 'output_tokens': 256, 'total_tokens': 283}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. PProvide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatpromt Template(Template is just a piece of text which tells the model how to behave)\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI Engineer. PProvide me answers based on the questions\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eaa925bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm\n",
    "response = chain.invoke({\"input\": \"Can you tell me about Langsmith?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9407a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Sure, here's an overview of Langsmith:\\n\\n**What is Langsmith?**\\n\\n* Langsmith is an open-source tool for **visualizing and understanding code structures and data relationships** within codebases. \\n* It supports various programming languages and data formats, including Python, Java, JavaScript, SQL, and more.\\n* It offers functionalities like **reverse engineering, tracing, highlighting, and searching** within code.\\n\\n**Benefits of using Langsmith:**\\n\\n* **Simplified code understanding:** It visually displays code relationships, making it easier to understand complex code structures.\\n* **Improved code documentation:** It automatically generates documentation for code, including variables, functions, and classes.\\n* **Enhanced debugging:** It helps identify errors and debugging issues quickly by visualizing the code flow.\\n* **Comparison with other tools:** It offers similar functionalities to other code visualization tools like Visual Studio Code, but with a focus on data relationships.\\n\\n**Use cases for Langsmith:**\\n\\n* **Software developers:** It can be used by developers to analyze and understand existing codebases.\\n* **QA testers:** It can help them identify bugs and understand the functionality of software systems.\\n* **Data scientists and analysts:** It can be used to explore and analyze data\", additional_kwargs={}, response_metadata={'model': 'gemma:2b', 'created_at': '2025-12-03T14:48:34.4616586Z', 'done': True, 'done_reason': 'length', 'total_duration': 116661945400, 'load_duration': 16579448600, 'prompt_eval_count': 45, 'prompt_eval_duration': 10908538700, 'eval_count': 256, 'eval_duration': 87389458500, 'logprobs': None, 'model_name': 'gemma:2b', 'model_provider': 'ollama'}, id='lc_run--1e15cd63-db20-4238-a9bc-be216302b7a3-0', usage_metadata={'input_tokens': 45, 'output_tokens': 256, 'total_tokens': 301})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d03e6df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Sure! Here's a summary of Langsmith:**\\n\\n**What is Langsmith?**\\n\\nLangsmith is an open-source AI language model that specializes in generating human-quality text, code, and other formats. It is a large language model (LLM) with a massive dataset of text and code, trained on a massive dataset of text and code.\\n\\n**Key features of Langsmith:**\\n\\n* **High-quality text generation:** Langsmith can generate various content, including text, code, scripts, emails, and more.\\n* **Multi-modal capabilities:** It can generate text in various formats, including images, audio, and video.\\n* **Domain-specific training:** It has been fine-tuned on a wide range of domains, such as healthcare, finance, and law.\\n* **Open-source licensing:** Langsmith is open-source under the Apache 2.0 license.\\n\\n**How can I use Langsmith?**\\n\\n* **Direct API access:** You can access Langsmith's API directly to generate text and other formats.\\n* **Cloud-based services:** Several cloud providers offer managed Langsmith services, including Google Cloud, Microsoft Azure, and Amazon Web Services.\\n* **Command-line\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## String Output Parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "response = chain.invoke({\"input\": \"Can you tell me about Langsmith?\"})\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae85f193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
